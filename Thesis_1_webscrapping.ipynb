{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as uReq\n",
    "import re\n",
    "import requests\n",
    "import bs4\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from os.path import basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_dict = {\"max-width:7%;\": \"1\", \"max-width:14%;\": \"2\", \"max-width:21%;\": \"3\", \n",
    "              \"max-width:28%;\": \"4\", \"max-width:35%;\": \"5\"} #1 being least 5 being most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dict = {\"Homme\": \"Male\", \"Femme\": \"Female\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_dict = {\"Acné\": \"Acne\", \"Allergie\":\"Allergy\", \"Allergie acariens\":\"Dust mite allergy\", \"Asthme\":\"Asthma\",\n",
    "               \"Ampoules - cloques\":\"Blisters - blisters\", \"Angine de poitrine\":\"Angina pectoris\",\n",
    "               \"Angoisse / trouble panique\":\"Anxiety\", \"Arrêter de fumer\":\"Stop smoking\", \"Bronchite\":\"Bronchitis\",\n",
    "               \"Arthrite psoriatique\":\"Psoriatic arthritis\", \"Arthrose\":\"Osteoarthritis\", \"Brûlures\":\"Burns\",\n",
    "               \"Arthrose colonne vertébrale\":\"Spine osteoarthritis\", \"Cancer du sein\":\"Breast cancer\",\n",
    "               \"Céphalées\":\"Headache\", \"Cholestérol élevé\":\"High cholesterol\", \"Couperose\":\"Rosacea\",\n",
    "               \"Colite ulcéreuse\":\"Ulcerative colitis\", \"Crise cardiaque\":\"Heart attack\", \"Tremblements\":\"Tremors\",\n",
    "               \"Complications post-opératoires\":\"Post-operative complications\", \"Démangeaison\":\"Itching\",\n",
    "               \"Cycle menstruel irrégulier\":\"Irregular menstrual cycle\", \"Défaillance nerveuse\":\"Nerve failure\",\n",
    "               \"Dépression\":\"Depression\", \"Dépression post-natale\":\"Post-natal depression\", \"Thyroïde\":\"Thyroid\",\n",
    "               \"Dépression chronique\":\"Depression\", \"Diabète type 1\":\"Type 1 diabetes\", \"TDAH\":\"ADHD\",\n",
    "               \"Diabète type 2\":\"Type 2 diabetes\", \"Diabète type 3\":\"Type 3 diabetes\", \"Urticaire\":\"Urticaria\",\n",
    "               \"Troubles d'angoisse\":\"Anxiety\", \"Trouble stress post-traumatique\":\"Post-traumatic stress disorder\",\n",
    "               \"Trouble schizotypique\":\"Schizotypal disorder\", \"Trouble rythme cardiaque\":\"Heart rhythm disorder\",\n",
    "               \"Trouble obsessionnel compulsif (TOC)\":\"Obsessive Compulsive Disorder (OCD)\", \"Psychose\":\"Psychosis\",\n",
    "               \"Trouble bipolaire / trouble mani dépressif\":\"Bipolar disorder / manic depressive disorder\",\n",
    "               \"Thyroïde enlevée\":\"Thyroid removed\", \"Tension élevée\":\"High tension\", \"Sinusite\":\"Sinusitis\",\n",
    "               \"Spondylarthrite ankylosante\":\"Ankylosing spondylitis\", \"Schizophrénie\":\"Schizophrenia\",\n",
    "               \"Rhume des foins\":\"Hay fever\", \"Rhumatisme\":\"Rheumatism\", \"Retour d'âge\":\"Return of age\",\n",
    "               \"Pyélonéphrite\":\"Pyelonephritis\", \"Problèmes psychiques\":\"Psychic problems\", \"Otite\":\"Otitis\",\n",
    "               \"Problèmes cardiaques\":\"Heart problems\", \"Pouls élevé\":\"High pulse\", \"Pneumonie\":\"Pneumonia\",\n",
    "               \"Polyneuropathie\":\"Polyneuropathy\", \"Phobie sociale\":\"Social phobia\", \"Narcolepsie\":\"Narcolepsy\",\n",
    "               \"MST (maladies sexuellement transmissibles)\":\"STDs (sexually transmitted diseases)\",\n",
    "               \"Mise en place stérilet\":\"IUD insertion\", \"Maladie de Lyme - borréliose\":\"Lyme disease - borreliosis\",\n",
    "               \"Maladie de Graves\":\"Graves disease\", \"Maladie de Crohn\":\"Crohn's disease\", \"Insomnie\":\"Insomnia\",\n",
    "               \"Maladie d'Hashimoto\":\"Hashimoto's disease\", \"Maladie auto-immunitaire\":\"Autoimmune disease\",\n",
    "               \"Mal de gorge\":\"Sore throat\", \"Inflammation articulaire\":\"Joint inflammation\", \"Hernie\":\"Hernia\",\n",
    "               \"Infection urinaire\":\"Urinary tract infection\", \"Infection gencive\":\"Gum infection\", \"Fatigue\":\"Tired\",\n",
    "               \"Infection des amygdales\":\"Infection of the tonsils\", \"Infection de la prostate\":\"Prostate infection\",\n",
    "               \"Infection de la machoire\":\"Jaw infection\", \"Infection de l'estomac\":\"Stomach infection\",\n",
    "               \"Infection dans la poitrine\":\"Chest Infection\", \"Infection bactérienne\":\"Bacterial infection\",\n",
    "               \"Infection (plaie)\":\"Infection (wound)\", \"Glande thyroïde lente\":\"Slow thyroid gland\",\n",
    "               \"Glande thyroïde hyperactive\":\"Overactive thyroid gland\", \"Fibromyalgie\":\"Fibromyalgia\",\n",
    "               \"Épisode maniaque\":\"Manic episode\", \"Épilepsie\":\"Epilepsy\", \"Douleur, général\":\"Pain, general\",\n",
    "               \"Douleurs menstruation\":\"Menstruation pain\", \"Douleur articulaire\":\"Articular pain\",\n",
    "               \"Douleur nerveuse\":\"Nerve pain\", \"Hypothyroïdie\":\"Hypothyroidism\", \"Battements de coeur\": \"Heartbeats\",\n",
    "               \"Ablation de la thyroïde\":\"Thyroid removal\", \"Pas dans la liste\":\"Other\", \"Apnée\":\"Apnea\",\n",
    "               \"Tendinite épaule\":\"Shoulder tendinitis\", \"Alcoolisme\":\"Alcoholism\", \"Mal aux dents\":\"Toothache\",\n",
    "               \"Syndrome des jambes sans repos\":\"Restless legs syndrome\", \"Vertige - tournis\":\"Vertigo - spinning\",\n",
    "               \"Cholestérol trop élevé\":\"High cholesterol\",\"Crampes jambes\":\"Leg cramps\", \"Acidité\":\"Acidity\",\n",
    "               \"Effet indésirable d'un autre médicament\":\"Side effect of another medicine\", \"Attaque\":\"Attack\",\n",
    "               \"Anémie suite déficience vitamine B12\":\"Anemia\", \"Défaillances cardiaques\":\"Cardiac failures\",\n",
    "               \"Brûlure d'estomac - acidité gastrique\":\"Heartburn - gastric acidity\", \"Sarcoïdose\":\"Sarcoidosis\",\n",
    "               \"Arthrite chronique juvénile\":\"Juvenile chronic arthritis\",\"Endométriose\":\"Endometriosis\",\n",
    "               \"Angoisses\":\"Anxiety\",\"Trouble d'angoisse\":\"Anxiety\", \"Bouche sèche\":\"Dry Mouth\",\n",
    "               \"Trouble dysthémie avec TDA\":\"Dysthemia disorder with ADD\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped anxiety together\n",
    "#some mnot translated like migraine and contraception\n",
    "#grouped high cholesterol and too high cholesterol\n",
    "#grouped depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.cut(age_range, bins=4, labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Collecting Data: webscrapping\n",
    "In order to obtain all the reviews for the different medicine, I scrapped the meamedica website. In order to analyse and proceed to text mine each medicine separatly later on, I decided to create one dataset for each medicine, all have the exact same format.\n",
    "\n",
    "## 1.1. Collecting Levothyrox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/glande-thyroide-hypothyroidie-a-action-lente/levothyrox'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Levothyrox\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('levothyrox_review.csv') #we store the dataframe in a csv file #use url to define file name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Collecting Mirena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/contraception-autre/mirena'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Mirena\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('mirena_review.csv') #we store the dataframe in a csv file #use url to define file name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Collecting Tramadol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/douleurs-morphine/tramadol'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Tramadol\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tramadol_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Collecting Paroxetine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/depression-antidepresseurs-irs/paroxetine'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Paroxetine\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('paroxetine_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Collecting Effexor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/depression-antidepresseurs-autre/effexor'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Effexor\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information for 1st element of subText\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('effexor_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Collecting Champix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/toxicomanie/champix'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Champix\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('champix_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. Collecting Lyrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/epilepsie/lyrica'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Lyrica\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('lyrica_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8. Collecting Simvastatine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/cholesterol/simvastatine'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Simvastine\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('simvastine_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9. Collecting Amoxicilline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/antibiotiques-penicillines-a-large-spectre/amoxicilline'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Amoxicilline\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('amoxicilline_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10. Collecting Sertraline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/depression-antidepresseurs-irs/sertraline'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Sertraline\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sertraline_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11. Collecting Cymbalta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/depression-antidepresseurs-autre/cymbalta'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Cymbalta\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cymbalta_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12. Collecting Seroplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/depression-antidepresseurs-irs/seroplex'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Seroplex\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('seroplex_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.13. Collecting Crestor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/cholesterol/crestor'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Crestor\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('crestor_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.14. Collecting Tamoxifene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/cancer-hormones-et-antihormones/tamoxifene'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Tamoxifene\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tamoxifene_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.15. Collecting Citalopram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/depression-antidepresseurs-irs/citalopram'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Citalopram\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('citalopram_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.16. Collecting Metformine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/diabetes-medicaments-oraux/metformine'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Metformine\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('metformine_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.17. Collecting Deroxat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/depression-antidepresseurs-irs/deroxat'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Deroxat\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('deroxat_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.18. Collecting Tahor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/cholesterol/tahor'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Tahor\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tahor_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.19. Collecting Victoza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/diabetes-medicaments-oraux/victoza'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Victoza\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('victoza_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.20. Collecting Propranolol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/tension-arterielle-beta-bloquant/propranolol'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Propranolol\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('propranolol_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.21. Collecting Abilify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/psychose-schizophrenie-antipsychotique/abilify'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Abilify\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('abilify_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.22. Collecting Concerta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/adhd-psychostimulants/concerta'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Concerta\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('concerta_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.23. Collecting Keppra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/epilepsie/keppra'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Keppra\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('keppra_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.24. Collecting Roaccutane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/acne/roaccutane'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Roaccutane\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('roaccutane_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.25. Collecting Lexapro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/depression-antidepresseurs-irs/lexapro'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Lexapro\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('lexapro_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.26. Collecting Aerius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/allergies/aerius'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Aerius\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('aerius_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.27. Collecting Valdoxan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/depression-antidepresseurs-autre/valdoxan'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Valdoxan\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('valdoxan_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.28. Collecting Cerazette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/contraception-autre/cerazette'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Cerazette\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cerazette_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.29. Collecting Doxycycline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/antibiotiques-tetracyclines/doxycycline'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Doxycycline\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan\n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('doxycycline_review.csv') #we store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.30. Collecting Methotrexate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we collect the urls 1-7 because other pages are not available\n",
    "url = 'https://www.meamedica.fr/systeme-immunitaire-immunosuppression/methotrexate'\n",
    "url = [url] + [url + '/' + str(i) for i in range(2, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We collect all pages for Methotrexate\n",
    "\n",
    "rx_dose = re.compile('\\((.*)\\)')\n",
    "\n",
    "rows = []\n",
    "for u in url:\n",
    "    html = requests.get(u).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for div_tag in soup.findAll('div', {'class': 'vote rounded btn-left'}): \n",
    "#note: there are some of these div_tag that contain boxes of text we do not want\n",
    "        row = {}\n",
    "        h3_tag = div_tag.find('h3')\n",
    "        if h3_tag is None:\n",
    "            continue #removes all the irrelevant <div class>:'vote rounded btn-left'\n",
    "        row['medicine'] = h3_tag.text.strip() #Picks up medicine name and assigns to row of that name\n",
    "        subtext_tag = div_tag.find('div', {'class': 'subText'}) \n",
    "        #div_tag contains multiple elements we want to store in different columns\n",
    "        subText = subtext_tag.text.split('\\r\\n') #use the \\ to seperate the information\n",
    "        var = subText[1].strip().split(' | ') #use the | to seperate the information\n",
    "        row['date'] = var[0] #takes first value in var\n",
    "        row['gender'] = var[1] #takes second value in var\n",
    "        row['age'] = var[2] if len(var)==3 else np.nan #takes 3rd value in var if it exists otherwise NaN\n",
    "        match = rx_dose.search(subText[3]) #takes 4th element of subText\n",
    "        row['dose'] = np.nan if match is None else match.group(1) #takes 2nd value in match if it exists otherwise NaN\n",
    "        row['disease'] = subText[4].strip() if len(subText)>4 else np.nan \n",
    "        span_tag = div_tag.find('span', {'class': 'initial-text'}) #finds up the review in its div_tag\n",
    "        row['comment'] = span_tag.text if span_tag else ''\n",
    "        for span_tag in div_tag.findAll('span', {'style': 'width:65%'}): #finds the width % of the 4 little graphs\n",
    "            text = span_tag.text\n",
    "            img_tag = span_tag.next_sibling.next_sibling\n",
    "            row[text] = img_tag.attrs['style'] if img_tag else ''\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['age']=df['age'].astype(float)\n",
    "df['age_range']=pd.cut(df['age'], [0,20,35,50,65,80,np.inf], labels = ['0-20','21-35','36-50','51-65','66-80','80+'])\n",
    "df['gender'].replace(gender_dict, inplace=True)\n",
    "df['disease'].replace(disease_dict, inplace=True)\n",
    "df[\"Efficacité\"].replace(width_dict, inplace=True)\n",
    "df[\"Quantité effets secondaires\"].replace(width_dict, inplace=True) \n",
    "df[\"Gravité effets secondaires\"].replace(width_dict, inplace=True)\n",
    "df[\"Facilité d'emploi\"].replace(width_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Efficacité\": \"efficiency\", \"Quantité effets secondaires\": \"quantity_of_secondary_effects\", \n",
    "                   \"Gravité effets secondaires\": \"severity_of_secondary_effects\", \"Facilité d'emploi\": \"ease_of_use\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('methotrexate_review.csv') #store the dataframe in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
